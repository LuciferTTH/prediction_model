{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Background（背景）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "临床结局一般是多因素共同作用的结果，在模型构建时，变量间常存在各种各样的关系，单因素分析由于无法考虑各变量之间的关系，结果往往不可靠，我们常常采用的解决方案是多因素的回归分析。在进行多因素的回归分析时，如何合理地进行变量筛选从而构建最佳模型是不可避免的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.筛选方法和函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestsubset_survivalWhen we build a prediction model, in nature, what we would like to do is to find a function $f()$ to make $Y=f(\\mathbf{X}, \\epsilon)$. The function $f()$ can be enumerous. Thus, The key step of prediction model building is to make some reasonable assumptions about the function form of $f()$, and these assumptions are called the hypothesis space of $f()$.\n",
    "\n",
    "当我们构建预测模型时，我们想去找到一个函数 $f()$ 使得 $Y=f(\\mathbf{X}, \\epsilon)$，函数 $f()$ 是多种多样的。因此，构建预测模型的关键步骤是对 $f()$ 的函数形式做出一些合理的假设，这些假设就称为 $f()$ 的假设空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis space of linear function ($f(\\mathbf{X}, \\epsilon)=\\mathbf{X} \\cdot \\beta^{T} + \\epsilon$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性函数的假设空间为 $f(\\mathbf{X}, \\epsilon)=\\mathbf{X} \\cdot \\beta^{T} + \\epsilon$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 Without additional restrictions（无额外限制的变量筛选方法）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we assume the hypothesis space is a space of linear function without any additional restriction. The key question now is to find the optimal combination of candicate predictors from the candidate predictor pool. During the process of finding the optimal combination, we have different searching strategies, each one of them is only a trade-off between complexity and best optimism. Basically, there are two types of searching strategies as follows.\n",
    "\n",
    "当我们假定该假设空间是一个无额外限制的线性函数空间时，关键问题就是从预测变量池中寻找候选预测变量的最佳组合。我们在寻找最佳模型的过程中有不同的模型变量筛选方法，但每一种方法仅是对模型复杂性和最优组合之间的权衡。以下将介绍两种常见的模型变量筛选方法\n",
    ">- 最优子集筛选法（best subset selection）\n",
    ">- 逐步选择法（stepwise selection）\n",
    ">>- 前进法（forward stepwise selection）\n",
    ">>- 后退法（backward stepwise selection）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 最优子集法（Best subset selection）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let $M_{0}$ denote the null model, which contains no predictors;\n",
    "2. For $k = 1, 2, \\cdots, p$\n",
    ">- Fit all ${p \\choose k}$ models that contain exactly $k$ predictors;\n",
    ">- Pick the best among these ${p \\choose k}$ models, and call it $M_{k}$; Here <span style=\"color:red\">best</span> is defined as having the smallest deviance ($D=-2l(0)$, for linear model, deviance is equal to residual sum of squares [RSS]), or equivalently the largest $R^{2}$ (coefficient of determination, $R^{2}=1-\\frac{SSR}{SST}$, generalized $R^{2}=1-(\\frac{l(0)}{l(\\hat{\\beta})})^{2/n}$);\n",
    "3. Select a single best model from among $M_{0}, \\cdots, M_{p}$ using cross-validated prediction error, AIC, BIC, ... ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 记 $M_{0}$ 为空模型，该模型中无预测变量，只存在截距项；\n",
    "2. 对于 $k = 1, 2, \\cdots, p$：\n",
    ">- 选取所有 ${p \\choose k}$ 个包含k个自变量的模型进行拟合；\n",
    ">- 从 ${p \\choose k}$ 个模型中选择最优模型，记为$M_{k}$（因为${p \\choose k}$个模型的自变量数均为k，所以此处最优模型可以通过最小的方差（$D=-2l(0)$）或最大的 $R^{2}$ 选取）；\n",
    "3. 从 $M_{0}, \\cdots, M_{p}$ 中选择一个最优模型，选取标准包括交叉验证的预测误差、AIC、BIC等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages and library them\n",
    "packages <- c(\"survival\",\n",
    "              \"survMisc\",\n",
    "              \"plyr\",\n",
    "              \"dplyr\",\n",
    "              \"glmnet\")\n",
    "\n",
    "for (i in packages) {\n",
    "    if (!suppressMessages(require(i, character.only = TRUE, quietly = TRUE))) {\n",
    "        install.packages(i, quietly = TRUE)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义函数\n",
    "# best subset\n",
    "Bestsubset_survival <- function(dataset, time, status, predictors, best_criteria = \"R2\"){\n",
    "    survival_outcome <- Surv(dataset[,time], dataset[,status])\n",
    "    list_of_reg_formulas <- lapply(seq_along((predictors)), function(n) {\n",
    "        left_hand_side  <- paste(\"Surv(\", time, \", \", status, \")\", sep =\"\")\n",
    "        right_hand_side <- apply(X = combn(predictors, n), MARGIN = 2, paste, collapse = \" + \")\n",
    "        paste(left_hand_side, right_hand_side, sep = \"  ~  \")\n",
    "    })\n",
    "    vector_of_reg_formulas <- unlist(list_of_reg_formulas)\n",
    "    \n",
    "    options(warn = -1)\n",
    "    list_of_reg_fits <- lapply(vector_of_reg_formulas, function(x) {\n",
    "        formula <- as.formula(x)\n",
    "        fit <- coxph(formula, data = dataset)\n",
    "        result_R2 <- summary(fit)$rsq\n",
    "        result_AIC <- extractAIC(fit)\n",
    "        \n",
    "        data.frame(No_predictors = result_AIC[1],\n",
    "                   R2 = result_R2[1], \n",
    "                   AIC = result_AIC[2],\n",
    "                   model = x)\n",
    "    })\n",
    "    options(warn = 0)\n",
    "    \n",
    "    res <- do.call(rbind, list_of_reg_fits)\n",
    "    if (best_criteria == \"R2\"){\n",
    "        formula <- res %>% \n",
    "            group_by(No_predictors) %>% \n",
    "            mutate(best_model = (R2 == max(R2))) %>% \n",
    "            filter(best_model) %>% \n",
    "            ungroup() %>% \n",
    "            mutate(model = as.character(model), optimal_model = (AIC == min(AIC))) %>% \n",
    "            filter(optimal_model) %>% \n",
    "            '[['('model')\n",
    "    }\n",
    "    if (best_criteria == \"AIC\"){\n",
    "        formula <- res %>% \n",
    "            group_by(No_predictors) %>% \n",
    "            mutate(best_model = (AIC == min(AIC))) %>% \n",
    "            filter(best_model) %>% \n",
    "            ungroup() %>% \n",
    "            mutate(model = as.character(model), optimal_model = (AIC == min(AIC))) %>% \n",
    "            filter(optimal_model) %>% \n",
    "            '[['('model')\n",
    "    }\n",
    "    return(formula)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 逐步选择法（stepwise selection）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （1）前进法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 记 $M_{0}$ 为空模型，该模型中无预测变量，只存在截距项；\n",
    "2. 对于 $k = 0, 1, \\cdots, p-1$：\n",
    ">- 拟合所有在 $M_{k}$ 模型基础上加入1个自变量的模型（共有$p-k$个模型）；\n",
    ">- 从 $p-k$ 个模型中选取 $R^{2}$ 最大的模型，记为$M_{k+1}$；\n",
    "3. 从 $M_{0}, \\cdots, M_{p}$ 中选择一个最优模型，选取标准包括交叉验证的预测误差、AIC、BIC等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Forwardstep\n",
    "Forwardstep_survival <- function(dataset, time, status, predictors){\n",
    "    selected_vars <- c()\n",
    "    models <- data.frame()\n",
    "    p <- length(predictors)\n",
    "    survival_outcome <- Surv(dataset[,time], dataset[,status])\n",
    "    \n",
    "    # null model(初始model) \n",
    "    null_model <- coxph(\n",
    "                as.formula(paste(\"Surv(\", time, \", \", status, \") ~ \",\n",
    "                                 \"1\", \n",
    "                                 sep = \"\")),\n",
    "                data = dataset) \n",
    "    result_R2 <- NA\n",
    "    result_AIC <- extractAIC(null_model)\n",
    "    models <- data.frame(\n",
    "                     No_predictors = result_AIC[1],\n",
    "                     R2 = NA,\n",
    "                     AIC = result_AIC[2])\n",
    "\n",
    "    for (k in 0:(p-1)) {\n",
    "        candidate_added_vars  <- setdiff(predictors, selected_vars)\n",
    "        # Generate p-k model by adding another predictor\n",
    "        results <- lapply(candidate_added_vars, function(x) {\n",
    "            formula <- paste(\"Surv(\", time, \", \", status, \") ~ \", \n",
    "                             paste(c(x, selected_vars),\n",
    "                                   collapse = \" + \"), sep = \"\")\n",
    "            fit <- coxph(as.formula(formula), data = dataset)\n",
    "            result_R2 <- summary(fit)$rsq\n",
    "            result_AIC <- extractAIC(fit)\n",
    "            data.frame(No_predictors = result_AIC[1],\n",
    "                        R2 = result_R2[1],\n",
    "                        AIC = result_AIC[2],\n",
    "                        added_var = x,\n",
    "                        formula = formula)\n",
    "        })\n",
    "        res <- do.call(rbind, results)\n",
    "        best_model <- res %>% \n",
    "                        mutate(best_model = (R2 == max(R2))) %>% \n",
    "                        filter(best_model)\n",
    "        added_var <-  best_model %>% '[['('added_var')\n",
    "        selected_vars <- c(selected_vars, added_var)\n",
    "        best_model$model_vars <- paste(selected_vars, collapse = \" + \")\n",
    "        models <- rbind.fill(models, best_model)\n",
    "    }\n",
    "    \n",
    "    train_model_forwardstep <- models[models$AIC == min(models$AIC),][,\"formula\"]\n",
    "    return(train_model_forwardstep)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### （补充）带有停止准则的前进法\n",
    "\n",
    "1. Let $M_{0}$ denote the null model, which contains no predictors; Let $M_{p}$ denote the full model, which contains all $p$ predictors;\n",
    "\n",
    "2. Repeat the following steps for $k = 1, \\cdots, p$ :\n",
    ">- Fit all $p-k+1 \\choose 1$ models by adding another predictor to model $M_{k-1}$;\n",
    ">- Pick the best model, call it $M_k$; Here <span style=\"color:red\">best</span> is defined as having the smallest deviance ($D=-2l(0)$, for linear model, deviance is equal to residual sum of squares [RSS]), or equivalently the largest $R^{2}$ (coefficient of determination, $R^{2}=1-\\frac{SSR}{SST}$, generalized $R^{2}=1-(\\frac{l(0)}{l(\\hat{\\beta})})^{2/n}$); or the samllest cross-validated prediction error, or the samllest AIC ($-2l(\\hat{\\beta} + 2k$), or the samllest BIC($-2l(\\hat{\\beta} + klog(n)$), ...\n",
    ">- Select a single best model between $M_{k-1}$ and $M_{k}$; \n",
    ">- Stop if the single best model is $M_{k-1}$ or $k = p$;\n",
    "\n",
    "3. The final model is $M_{k-1}$ or $M_{p}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "1.定义$M_{0}$为空模型，不含任何预测变量；定义$M_{p}$为全模型，含有全部 $p$ 个预测变量；\n",
    "\n",
    "2.对于 $k = 1,\\cdots, p$，重复以下步骤：\n",
    "    \n",
    ">- 通过为模型 $M_{k-1}$添加1个预测变量，拟合所有的$p-k+1 \\choose 1$ 个模型\n",
    ">- 选择最优模型，记为$M_{k}$；此处最优模型可以通过最小的方差[$D=-2l(0)$，对于线性模型而言，方差等同于残差平方和(RSS)]，或最大的 $R^{2}$ [决定系数, $R^{2}=1-\\frac{SSR}{SST}$, 广义 $R^{2}=1-(\\frac{l(0)}{l(\\hat{\\beta})})^{2/n}$]，或最小的交叉验证的预测误差，或最小的AIC[$-2l(\\hat{\\beta} + 2k$]，或最小的BIC[$-2l(\\hat{\\beta} + klog(n)$]选取...\n",
    ">- 从 $M_{k-1}$和$M_{k}$之间选择一个最好的模型；\n",
    ">- 当该模型是$M_{k-1}$或$k = p$的时候，停止该过程；\n",
    "\n",
    "3.最终的模型为$M_{k-1}$ 或 $M_{p}$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Forwardstep with stop criteria(也可以用step()函数)\n",
    "ForwardstepwithStop_survival <- function(dataset, time, status, predictors){\n",
    "    selected_vars <- c()\n",
    "    p <- length(predictors)\n",
    "    null_model <- coxph(as.formula(\n",
    "                        paste(\"Surv(\", time, \", \", status, \") ~ \", \n",
    "                              \"1\", \n",
    "                              sep = \"\")),\n",
    "                        data = dataset) # null model\n",
    "    result_R2 <- NA\n",
    "    AIC_min <- extractAIC(null_model)[2]\n",
    "    \n",
    "    for (k in 1:p) {\n",
    "        candidate_added_vars  <- setdiff(predictors, selected_vars)\n",
    "        # Generate p-k+1 model by adding another predictor\n",
    "        results <- lapply(candidate_added_vars, function(x){\n",
    "            formula <- paste(\"Surv(\", time, \", \", status, \") ~ \", \n",
    "                             paste(c(x, selected_vars),\n",
    "                                   collapse = \" + \"), sep = \"\")\n",
    "            fit <- coxph(as.formula(formula), data = dataset)\n",
    "            result_R2 <- summary(fit)$rsq\n",
    "            result_AIC <- extractAIC(fit)\n",
    "            data.frame(\n",
    "                No_predictors = result_AIC[1],\n",
    "                R2 = result_R2[1],\n",
    "                AIC = result_AIC[2],\n",
    "                added_var = x,\n",
    "                formula = formula)\n",
    "        })\n",
    "        res <- do.call(rbind, results)\n",
    "\n",
    "        if (min(res$AIC) < AIC_min) { \n",
    "            added_var <- res %>% \n",
    "                    mutate(best_model = (AIC == min(AIC))) %>% \n",
    "                    filter(best_model) %>% \n",
    "                    '[['('added_var')\n",
    "            selected_vars <- c(selected_vars, added_var)\n",
    "            k = k + 1\n",
    "            AIC_min <- min(res$AIC)\n",
    "        } else {\n",
    "            break \n",
    "            # Stop if the single best model is $M_{k-1}$\n",
    "        }\n",
    "    }\n",
    "    final_model <- paste(\"Surv(\", time, \", \", status, \") ~ \", \n",
    "                         paste(selected_vars, collapse = \" + \"), \n",
    "                         sep = \"\")\n",
    "    return(final_model)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）后退法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 记 $M_{p}$ 为包含所有自变量的全模型；\n",
    "2. 对于 $k = p, p-1, \\cdots, 1$：\n",
    ">- 拟合所有在 $M_{k}$ 模型基础上减少1个自变量的模型（共有$k$个模型）；\n",
    ">- 从$k$个模型中选取 $R^{2}$ 最大的模型，记为$M_{k-1}$；\n",
    "3. 从 $M_{0}, \\cdots, M_{p}$ 中选择一个最优模型，选取标准包括交叉验证的预测误差、AIC、BIC等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Backwardstep\n",
    "Backwardstep_survival <- function(dataset, time, status, predictors){\n",
    "    selected_vars <- predictors\n",
    "    models <- data.frame()\n",
    "    p <- length(predictors)\n",
    "    # full model(初始model) \n",
    "    full_model <- coxph(\n",
    "                as.formula(paste(\"Surv(\", time, \", \", status, \") ~ \",\n",
    "                                 paste(predictors, collapse = \"+\"), \n",
    "                                 sep = \"\")),\n",
    "                data = dataset)\n",
    "    result_R2 <- summary(full_model)$rsq\n",
    "    result_AIC <- extractAIC(full_model)\n",
    "    models <- data.frame(\n",
    "                 No_predictors = result_AIC[1],\n",
    "                 R2 = result_R2[1],\n",
    "                 AIC = result_AIC[2])\n",
    "    \n",
    "    for (k in p:1) {\n",
    "        if (k == 1) {\n",
    "            null_model <- coxph(\n",
    "                            as.formula(paste(\"Surv(\", time, \", \", status, \") ~ \",\n",
    "                                             \"1\", \n",
    "                                             sep = \"\")),\n",
    "                            data = dataset) # null model\n",
    "            result_R2 <- NA\n",
    "            result_AIC <- extractAIC(null_model)\n",
    "            best_model <- data.frame(\n",
    "                                 No_predictors = result_AIC[1],\n",
    "                                 R2 = NA,\n",
    "                                 AIC = result_AIC[2])\n",
    "            models <- rbind.fill(models, best_model)\n",
    "        }\n",
    "        if (k > 1) {\n",
    "            # Generate k model by remove a predictor\n",
    "            candidate_vars <- selected_vars\n",
    "            \n",
    "            results <- lapply(candidate_vars, function(x){\n",
    "                formula <- paste(\"Surv(\", time, \", \", status, \") ~ \",\n",
    "                                 paste(setdiff(selected_vars, x), collapse = \" + \"), \n",
    "                                 sep = \"\")\n",
    "                fit <- coxph(as.formula(formula), data=dataset)\n",
    "                result_R2 <- summary(fit)$rsq\n",
    "                result_AIC <- extractAIC(fit)\n",
    "\n",
    "                data.frame(No_predictors = result_AIC[1],\n",
    "                            R2 = result_R2[1], \n",
    "                            AIC = result_AIC[2],\n",
    "                            dropped_var = x,\n",
    "                            formula = as.character(formula))\n",
    "            })\n",
    "\n",
    "            res <- do.call(rbind, results)\n",
    "            best_model <- res %>% \n",
    "                            mutate(best_model = (R2 == max(R2))) %>% \n",
    "                            filter(best_model)\n",
    "            dropped_var <-  best_model %>% '[['('dropped_var')\n",
    "            selected_vars <- setdiff(selected_vars, dropped_var)\n",
    "            best_model$model_vars <- paste(selected_vars, collapse = \" + \")\n",
    "            models <- rbind.fill(models, best_model)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    train_model_backwardstep <- models[models$AIC == min(models$AIC),][,\"formula\"]\n",
    "    return(train_model_backwardstep)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （补充）带有停止准则的后退法\n",
    "\n",
    "1. Let $M_{p}$ denote the full model, which contains all $p$ predictors; Let $M_{0}$ denote the null model, which contains no predictors;\n",
    "\n",
    "2. Repeat the folloing steps for $k = p, \\cdots, 1$:\n",
    "\n",
    ">- Fit all $k \\choose 1$ models by dropping one predictor from model $M_{k}$;\n",
    ">- Pick the best model, call it $M_{k-1}$; Here <span style=\"color:red\">best</span> is defined as having the smallest deviance ($D=-2l(0)$, for linear model, deviance is equal to residual sum of squares [RSS]), or equivalently the largest $R^{2}$ (coefficient of determination, $R^{2}=1-\\frac{SSR}{SST}$, generalized $R^{2}=1-(\\frac{l(0)}{l(\\hat{\\beta})})^{2/n}$); or the samllest cross-validated prediction error, or the samllest AIC ($-2l(\\hat{\\beta} + 2k$), or the samllest BIC($-2l(\\hat{\\beta} + klog(n)$), ...\n",
    ">- Select a single best model between $M_{k-1}$ and $M_{k}$; \n",
    ">- Stop if the single best model is $M_{k}$ or $k = 1$;\n",
    "\n",
    "3. The final model is $M_{k}$ or $M_{1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义$M_{p}$为全模型，含有全部 $p$ 个预测变量；定义$M_{0}$为空模型，不含任何预测变量；\n",
    "\n",
    "2. 对于$k = p, \\cdots, 1$ ，重复以下步骤：\n",
    ">- 通过减少 $M_{k}$模型一个预测变量的方法，拟合所有的$k \\choose 1$ 个模型；\n",
    ">- 选择最优模型，记为$M_{k-1}$；此处最优模型可以通过最小的方差（$D=-2l(0)$，对于线性模型而言，方差等同于残差平方和[RSS]），\n",
    "或最大的 $R^{2}$ (决定系数, $R^{2}=1-\\frac{SSR}{SST}$, 广义 $R^{2}=1-(\\frac{l(0)}{l(\\hat{\\beta})})^{2/n}$)，\n",
    "或最小的交叉验证的预测误差，或最小的AIC($-2l(\\hat{\\beta} + 2k$)，或最小的BIC($-2l(\\hat{\\beta} + klog(n)$)选取；\n",
    ">- 从 $M_{k-1}$和$M_{k}$之间选择一个最好的模型；\n",
    ">- 当该模型是$M_{k}$或$k = 1$的时候，停止该过程；                                                 \n",
    "\n",
    "3. 最终模型为$M_{k}$或$k = 1$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Backwardstep with stop criteria (也可以用step()函数)\n",
    "BackwardstepwithStop_survival <- function(dataset, time, status, predictors){    \n",
    "    p <- length(predictors)\n",
    "    selected_vars <- predictors\n",
    "    survival_outcome <- Surv(dataset[,time], dataset[,status])\n",
    "    \n",
    "    # 创建一个全模型(初始模型)\n",
    "    full_model <- coxph(as.formula(paste(\"survival_outcome\", \n",
    "                                   paste(predictors, collapse = \" + \"), \n",
    "                                   sep = \" ~ \")), \n",
    "                        data = dataset) \n",
    "    AIC_min <- extractAIC(full_model)[2]\n",
    "    \n",
    "    for (k in p:1) {\n",
    "        # Generate k model by remove a predictor\n",
    "        candidate_vars <- selected_vars\n",
    "        \n",
    "        if ((k > 1)) {\n",
    "            results <- lapply(candidate_vars, function(x){\n",
    "                formula <- paste(\"survival_outcome\", \n",
    "                                 paste(setdiff(candidate_vars, x), collapse = \" + \"), \n",
    "                                 sep = \" ~ \")\n",
    "                \n",
    "                fit <- coxph(as.formula(formula), data = dataset)\n",
    "                \n",
    "                result_R2 <- summary(fit)$rsq\n",
    "                \n",
    "                result_AIC <- extractAIC(fit)\n",
    "\n",
    "                data.frame(No_predictors = result_AIC[1],\n",
    "                    R2 = result_R2[1], \n",
    "                    AIC = result_AIC[2],\n",
    "                    dropped_var = x)\n",
    "            })\n",
    "            res <- do.call(rbind, results)\n",
    "            if (min(res$AIC) <= AIC_min){ \n",
    "                dropped_var <- res %>% \n",
    "                    mutate(best_model = (AIC == min(AIC))) %>% \n",
    "                    filter(best_model) %>% \n",
    "                    '[['('dropped_var')\n",
    "                selected_vars <- setdiff(candidate_vars, dropped_var)\n",
    "                k = k - 1\n",
    "                AIC_min <- min(res$AIC)\n",
    "            } else {\n",
    "                break \n",
    "                # Stop if the single best model is $M_{k}$\n",
    "            }\n",
    "        }\n",
    "        if (k == 1) {\n",
    "            # drop one variable will make a null model\n",
    "            null_model <- coxph(\n",
    "                            as.formula(paste(\"survival_outcome\", \"1\", sep = \" ~ \")),\n",
    "                            data = dataset) # null model\n",
    "            result_R2 <- NA\n",
    "            result_AIC <- extractAIC(null_model)\n",
    "            if (result_AIC[2] <= AIC_min) {\n",
    "                selected_vars <- c()\n",
    "            } else {\n",
    "                break \n",
    "                # Stop if the single best model is $M_{k}$\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    final_model <- paste(\"Surv(\", time, \", \", status, \") ~ \", \n",
    "                         paste(selected_vars, collapse = \" + \"), \n",
    "                         sep = \"\")\n",
    "    return(final_model)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）双向选择法\n",
    "\n",
    "1. Let $M_{p}$ denote the full model, which contains all $p$ predictors; Let $M_{0}$ denote the null model, which contains no predictors;\n",
    "2. Start from null model, for any model includ k predictors:\n",
    "3. Forward selection, for the rest of $p-k$ predictors:\n",
    ">- Fit all $p-k \\choose 1$ models by adding another predictor from the rest of $p-k$ predictors to best model between $M_{k-1}$ and $M_{k}$;\n",
    ">- Pick the best model, call it $M_{k+1}$; Here <span style=\"color:red\">best</span> is defined as having the smallest deviance ($D=-2l(0)$, for linear model, deviance is equal to residual sum of squares [RSS]), or equivalently the largest $R^{2}$ (coefficient of determination, $R^{2}=1-\\frac{SSR}{SST}$, generalized $R^{2}=1-(\\frac{l(0)}{l(\\hat{\\beta})})^{2/n}$); or the samllest cross-validated prediction error, or the samllest AIC ($-2l(\\hat{\\beta} + 2k$), or the samllest BIC($-2l(\\hat{\\beta} + klog(n)$);\n",
    ">- Select a single best model between $M_{k+1}$ and $M_{k}$; \n",
    "\n",
    "4. If add another predictor, then Backward selection\n",
    ">- Fit all $k \\choose 1$ models by drop one predictor from model $M_{k+1}$;\n",
    ">- Pick the best model, call it $Mb_{k}$; Here <span style=\"color:red\">best</span> is defined as having the smallest deviance ($D=-2l(0)$, for linear model, deviance is equal to residual sum of squares [RSS]), or equivalently the largest $R^{2}$ (coefficient of determination, $R^{2}=1-\\frac{SSR}{SST}$, generalized $R^{2}=1-(\\frac{l(0)}{l(\\hat{\\beta})})^{2/n}$); or the samllest cross-validated prediction error, or the samllest AIC ($-2l(\\hat{\\beta} + 2k$), or the samllest BIC($-2l(\\hat{\\beta} + klog(n)$);\n",
    ">- Select a single best model between $M_{k}$ and $M_{k+1}$;\n",
    "\n",
    "5. Stop if the single best model is $M_{k}$, otherwise repeat 3 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. 定义$M_{p}$为全模型，含有全部 $p$ 个预测变量；定义$M_{0}$为空模型，不含任何预测变量；\n",
    "2. 从空模型开始，对任何一个含有k个预测变量的模型（进行以下操作）：\n",
    "3. 前进选择法：对于剩下的$p-k$个预测变量（进行以下操作）：\n",
    ">- 通过向模型$M_{k-1}$与模型$M_{k}$之间的最优模型增添一个剩余的$p-k$个预测变量之一的方法，拟合所有 $p-k \\choose 1$ 个模型；\n",
    ">- 选取最优模型，记作$M_{k+1}$，最优模型可以通过最小的方差（$D=-2l(0)$，对于线性模型而言，方差等同于残差平方和[RSS]），\n",
    "或最大的 $R^{2}$ (决定系数, $R^{2}=1-\\frac{SSR}{SST}$, 广义 $R^{2}=1-(\\frac{l(0)}{l(\\hat{\\beta})})^{2/n}$)，\n",
    "或最小的交叉验证的预测误差，或最小的AIC($-2l(\\hat{\\beta} + 2k$)，或最小的BIC($-2l(\\hat{\\beta} + klog(n)$)选取；\n",
    ">- 从 $M_{k+1}$和$M_{k}$之间选择一个最优模型；\n",
    "4. 每增加了一个预测变量，同时也进行后退选择（进行以下操作）：\n",
    ">- 通过减少 $M_{k+1}$模型一个预测变量的方法，拟合所有的$k \\choose 1$ 个模型；\n",
    ">- 选取最优模型，记作$M_{k}$，最优模型可以通过最小的方差（$D=-2l(0)$，对于线性模型而言，方差等同于残差平方和[RSS]），\n",
    "或最大的 $R^{2}$ (决定系数, $R^{2}=1-\\frac{SSR}{SST}$, 广义 $R^{2}=1-(\\frac{l(0)}{l(\\hat{\\beta})})^{2/n}$)，\n",
    "或最小的交叉验证的预测误差，或最小的AIC($-2l(\\hat{\\beta} + 2k$)，或最小的BIC($-2l(\\hat{\\beta} + klog(n)$)选取；\n",
    ">- 从 $M_{k}$和$M_{k+1}$之间选择一个最优模型；\n",
    "5. 当最优模型是$M_{k}$时,停止该筛选过程，否则不断重复过程3与过程4。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary（总结）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 前进法（模型中的自变量从无到有、由少到多逐个引入回归方程）\n",
    "\n",
    "1. 优点：可以自动去掉高度相关的自变量。\n",
    "2. 局限性：后续变量的进入可能会使先进入方程的自变量变得无统计学意义。\n",
    "\n",
    "##### 后退法（先将全部自变量放入模型，然后逐步剔除无统计学意义的自变量）\n",
    "\n",
    "1. 优点：考虑到自变量的组合作用。\n",
    "2. 局限性：自变量数目较多或某些自变量高度相关时，可能会得到错误的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 逐步选择法与最优子集法的区别\n",
    "\n",
    "最优子集选择法可以选择任意变量进行建模，而逐步选择法只能基于之前所选的k个变量进行(k+1)轮建模，所以逐步选择法不能保证最优，因为前面的变量选择中很有可能选中一些不是很重要的变量（或在专业背景下不好解释的变量），但在后面的迭代中也必须加上，从而就不一定能产生最优变量组合。但优势是计算量大大减小，因此实用性更强。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 With additional restrictions（带额外限制条件的变量筛选方法）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 LASSO回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO回归引入正则化方法（L1-范数），使 $L({β_{1},..., β_{p}})+λ\\sum|β_{j}|$ 最小，通过在模型估计中增加惩罚项（$\\sum|β_{j}|$）压缩回归系数减小方差。由于LASSO回归可以将预测变量的估计系数压缩到0，因此可以在压缩系数的同时起到变量筛选的作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 将所有预测变量放入模型，建立LASSO回归；\n",
    "2. LASSO回归为寻找最佳的模型，引入惩罚值 λ(lambda)，随着λ值增加，各变量的回归系数β减小，有些会被压缩为0，说明这些变量在该λ值下对模型贡献很小可以剔除。因此，λ值决定了回归系数被压缩的程度从而决定最后纳入模型的预测变量；\n",
    "3. 确定最佳λ值，以下为两种常见方法：\n",
    ">- 采用十折交叉验证，计算不同 λ值下的Partial-likelihood deviance，一般选择最小Partial-likelihood deviance一个标准误时对应的λ值（虽然理论上选Partial-likelihood deviance最小时所对应的λ值，但λ值过小，回归系数压缩幅度较小，不一定能较好解决模型过拟合和共线性的问题）；\n",
    ">- 计算各模型的AIC、BIC等，选取AIC或BIC最小时对应的λ值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Lasso_survival <- function(dataset, time, status, predictors, lambda = \"min\"){\n",
    "    set.seed(123)\n",
    "    survival_outcome <- Surv(dataset[,time], dataset[,status])\n",
    "    x <- data.matrix(dataset[,predictors])\n",
    "    fit <- glmnet(x, survival_outcome, family=\"cox\", alpha=1)\n",
    "    \n",
    "    # 可视化结果\n",
    "    plot(fit, xvar=\"lambda\", label=T)\n",
    "    \n",
    "    # 使用交叉验证来确定最佳的λ\n",
    "    cv.fit <- cv.glmnet(x, survival_outcome, family=\"cox\", alpha = 1)\n",
    "    plot(cv.fit)\n",
    "    \n",
    "    if (lambda == \"1se\"){\n",
    "        coef1 <- predict(fit, s=cv.fit$lambda.1se, type = \"coefficients\")\n",
    "        print(coef1)\n",
    "        selected_vars <- coef1@Dimnames[[1]][coef1@i]\n",
    "    }\n",
    "    \n",
    "    if (lambda == \"min\"){\n",
    "        coef2 <- predict(fit, s=cv.fit$lambda.min, type = \"coefficients\")\n",
    "        print(coef2)\n",
    "        selected_vars <- coef2@Dimnames[[1]][coef2@i+1]\n",
    "    }\n",
    "    \n",
    "    lasso_model <- paste(\"Surv(\", time, \", \", status, \") ~ \", paste(selected_vars, collapse = \" + \"), sep = \"\")\n",
    "    return(lasso_model)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Simulation（模拟）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load('dataset_after_description.R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform factor variables to dummy variables\n",
    "dataset <- dataset %>% \n",
    "    mutate(albuminuria_moderate = as.numeric(albuminuria == \"moderate\"),\n",
    "           albuminuria_severe = as.numeric(albuminuria == \"severe\"),\n",
    "           CKD_stage_G3a = as.numeric(CKD_stage == \"G3a\"),\n",
    "           CKD_stage_G3b = as.numeric(CKD_stage == \"G3b\"),\n",
    "           CKD_stage_G4 = as.numeric(CKD_stage == \"G4\"))\n",
    "\n",
    "# 待筛选变量\n",
    "predictors <- c('age', 'age_square', 'male', \n",
    "                # 'BMI', 'SBP', \n",
    "                # 'MI', 'HF', 'COPD', 'cancer', 'liver_disease', 'hypoglycemia', \n",
    "                'TC_rcs_1', 'TC_rcs_2', 'TC_rcs_3', 'log_LDLC', \n",
    "                'albuminuria_moderate', 'albuminuria_severe', \n",
    "                'CKD_stage_G3a', 'CKD_stage_G3b', 'CKD_stage_G4',\n",
    "                # 'No_outpatient', 'No_inpatient', \n",
    "                # 'age_male', 'male_cancer', \n",
    "                'male_CKD_stage_G3a', 'male_CKD_stage_G3b', 'male_CKD_stage_G4', \n",
    "                'age_TC', 'age_BMI_TC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.1 Without additional restrictions（无额外限制条件的变量筛选方法）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 最优子集法（Best subset selection）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_model_bestsubset <- Bestsubset_survival(data=dataset, time=\"AKI_time\", status=\"AKI_status\", , predictors = predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_bestsubset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 逐步选择法（stepwise selection）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （1）前进法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Surv(AKI_time, AKI_status) ~ age_TC + male + age + age_BMI_TC + male_CKD_stage_G3a + albuminuria_severe + TC_rcs_1 + TC_rcs_3'"
      ],
      "text/latex": [
       "'Surv(AKI\\_time, AKI\\_status) \\textasciitilde{} age\\_TC + male + age + age\\_BMI\\_TC + male\\_CKD\\_stage\\_G3a + albuminuria\\_severe + TC\\_rcs\\_1 + TC\\_rcs\\_3'"
      ],
      "text/markdown": [
       "'Surv(AKI_time, AKI_status) ~ age_TC + male + age + age_BMI_TC + male_CKD_stage_G3a + albuminuria_severe + TC_rcs_1 + TC_rcs_3'"
      ],
      "text/plain": [
       "[1] \"Surv(AKI_time, AKI_status) ~ age_TC + male + age + age_BMI_TC + male_CKD_stage_G3a + albuminuria_severe + TC_rcs_1 + TC_rcs_3\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model_forwardstep <- Forwardstep_survival(data=dataset, time=\"AKI_time\", status=\"AKI_status\", predictors = predictors)\n",
    "train_model_forwardstep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "采用逐步选择法（前进法）筛选得到的变量有age_TC，male，age，age_BMI_TC，male_CKD_stage_G3a，albuminuria_severe，TC_rcs_1，TC_rcs_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (补充)带有停止准则的前进法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Surv(AKI_time, AKI_status) ~ male + age + age_BMI_TC + male_CKD_stage_G3a'"
      ],
      "text/latex": [
       "'Surv(AKI\\_time, AKI\\_status) \\textasciitilde{} male + age + age\\_BMI\\_TC + male\\_CKD\\_stage\\_G3a'"
      ],
      "text/markdown": [
       "'Surv(AKI_time, AKI_status) ~ male + age + age_BMI_TC + male_CKD_stage_G3a'"
      ],
      "text/plain": [
       "[1] \"Surv(AKI_time, AKI_status) ~ male + age + age_BMI_TC + male_CKD_stage_G3a\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model_forwardstepwithstop <- ForwardstepwithStop_survival(data=dataset, time=\"AKI_time\", status=\"AKI_status\", predictors = predictors)\n",
    "train_model_forwardstepwithstop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用带有停止准则的前进法筛选得到的预测变量有male，age，age_BMI_TC，male_CKD_stage_G3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surv(AKI_time, AKI_status) ~ male + age + age_BMI_TC + male_CKD_stage_G3a"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 使用Step()\n",
    "# 创建一个全模型(初始模型)\n",
    "time <- \"AKI_time\"\n",
    "status <- \"AKI_status\"\n",
    "full_model <- coxph(as.formula(paste(\"Surv(\", time, \", \", status, \") ~ \",  \n",
    "                               paste(predictors, collapse = \" + \"), \n",
    "                               sep = \"\")), \n",
    "                    data = dataset)\n",
    "null_model <- coxph(as.formula(paste(\"Surv(\", time, \", \", status, \") ~ \", \n",
    "                               \"1\", \n",
    "                               sep = \"\")), \n",
    "                    data = dataset)\n",
    "train_model_forwardstepfunction <- step(null_model, direction = \"forward\", scope = list(upper = formula(full_model), lower = formula(null_model)), trace=0)\n",
    "train_model_forwardstepfunction$formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用Step()函数(筛选方法为“向前选择”)筛选得到的预测变量有male，age，age_BMI_TC，male_CKD_stage_G3a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）后退法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Surv(AKI_time, AKI_status) ~ male + TC_rcs_1 + TC_rcs_3 + male_CKD_stage_G3a + age_TC + age_BMI_TC'"
      ],
      "text/latex": [
       "'Surv(AKI\\_time, AKI\\_status) \\textasciitilde{} male + TC\\_rcs\\_1 + TC\\_rcs\\_3 + male\\_CKD\\_stage\\_G3a + age\\_TC + age\\_BMI\\_TC'"
      ],
      "text/markdown": [
       "'Surv(AKI_time, AKI_status) ~ male + TC_rcs_1 + TC_rcs_3 + male_CKD_stage_G3a + age_TC + age_BMI_TC'"
      ],
      "text/plain": [
       "[1] \"Surv(AKI_time, AKI_status) ~ male + TC_rcs_1 + TC_rcs_3 + male_CKD_stage_G3a + age_TC + age_BMI_TC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model_backwardstep <- Backwardstep_survival(data=dataset, time=\"AKI_time\", status=\"AKI_status\", predictors = predictors)\n",
    "train_model_backwardstep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用逐步选择法（后退法）筛选得到的变量有male，TC_rcs_1，TC_rcs_3，male_CKD_stage_G3a，age_TC，age_BMI_TC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (补充)带有停止准则的后退法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Surv(AKI_time, AKI_status) ~ male + TC_rcs_1 + TC_rcs_3 + male_CKD_stage_G3a + age_TC + age_BMI_TC'"
      ],
      "text/latex": [
       "'Surv(AKI\\_time, AKI\\_status) \\textasciitilde{} male + TC\\_rcs\\_1 + TC\\_rcs\\_3 + male\\_CKD\\_stage\\_G3a + age\\_TC + age\\_BMI\\_TC'"
      ],
      "text/markdown": [
       "'Surv(AKI_time, AKI_status) ~ male + TC_rcs_1 + TC_rcs_3 + male_CKD_stage_G3a + age_TC + age_BMI_TC'"
      ],
      "text/plain": [
       "[1] \"Surv(AKI_time, AKI_status) ~ male + TC_rcs_1 + TC_rcs_3 + male_CKD_stage_G3a + age_TC + age_BMI_TC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model_backwardstepwithstop <- BackwardstepwithStop_survival(data=dataset, time=\"AKI_time\", status=\"AKI_status\", predictors = predictors)\n",
    "train_model_backwardstepwithstop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用带有停止准则的后退法筛选得到的预测变量有male，TC_rcs_1，TC_rcs_3，male_CKD_stage_G3a，age_TC，age_BMI_TC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surv(AKI_time, AKI_status) ~ male + TC_rcs_1 + TC_rcs_3 + male_CKD_stage_G3a + \n",
       "    age_TC + age_BMI_TC"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 使用Step()\n",
    "# 创建一个全模型(初始模型)\n",
    "full_model <- coxph(as.formula(paste(\"Surv(\", time, \", \", status, \") ~ \", \n",
    "                               paste(predictors, collapse = \" + \"), \n",
    "                               sep = \"\")), \n",
    "                    data = dataset)\n",
    "null_model <- coxph(as.formula(paste(\"Surv(\", time, \", \", status, \") ~ \", \n",
    "                               \"1\", \n",
    "                               sep = \"\")), \n",
    "                    data = dataset)\n",
    "train_model_backwardstepfunction <- step(full_model, direction = \"backward\", scope = list(upper = formula(full_model), lower = formula(null_model)), trace=0)\n",
    "train_model_backwardstepfunction$formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用Step()函数(筛选方法为“向后选择”)筛选得到的预测变量有male，TC_rcs_1，TC_rcs_3，male_CKD_stage_G3a，age_TC，age_BMI_TC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 With additional restrictions（带额外限制条件的变量筛选方法）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 LASSO回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAP1BMVEUAAAAil+Yo4uVNTU1h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\nBAggJEAAIQEC/g/th8yh1syWHwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 x 1 sparse Matrix of class \"dgCMatrix\"\n",
      "                                1\n",
      "age                  9.749135e-03\n",
      "age_square           2.400645e-05\n",
      "male                 3.422981e-01\n",
      "TC_rcs_1             .           \n",
      "TC_rcs_2             .           \n",
      "TC_rcs_3             .           \n",
      "log_LDLC             .           \n",
      "albuminuria_moderate .           \n",
      "albuminuria_severe   .           \n",
      "CKD_stage_G3a        .           \n",
      "CKD_stage_G3b        .           \n",
      "CKD_stage_G4         .           \n",
      "male_CKD_stage_G3a   6.399917e-02\n",
      "male_CKD_stage_G3b   .           \n",
      "male_CKD_stage_G4    .           \n",
      "age_TC               .           \n",
      "age_BMI_TC           1.899753e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nAAL8D4ccB7pAjzROAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model_lasso <- Lasso_survival(data=dataset, time=\"AKI_time\", status=\"AKI_status\", predictors = predictors, lambda = \"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图1为LASSO筛选变量动态过程图，一条彩色线代表一个变量的回归系数β值的变化，x轴为惩罚值，x轴上方为在该值下的剩余变量数。随着λ增加，各变量的回归系数β在减小，有些变为0，说明该变量在此时对模型贡献微乎其微可以剔除。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图2展示了Partial-likelihood deviance随Log(λ)变化曲线，图中给出了两个惩罚值λ：\n",
    "1. Partial-likelihood deviance最小时的λ值，即lambda.min； \n",
    "2. 最小Partial-likelihood deviance一个标准误时对应的λ值，即lambda.1se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "λ=lambda.min时，给出的是一个具备优良性能且自变量个数最少的模型，因此LASSO回归筛选出的变量为age, age_square, male, male_CKD_stage_G3a, age_BMI_TC。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上，模型预测的精确性有时可以通过压缩或者令某些系数为0来提高，通过损失一点偏差（bias）来降低预测值的方差，从而可能提高整个模型预测的精确性。此外，当有大量的预测变量时，我们经常去筛选一个小的子集来进行模型构建，防止模型的过拟合，我们愿意损失一点解释度。以上为模型变量筛选常用的3种方法，在实际运用中还需要结合具体的临床背景对预测变量进一步筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Surv(AKI_time, AKI_status) ~ age + age_square + male + male_CKD_stage_G3a + age_BMI_TC'"
      ],
      "text/latex": [
       "'Surv(AKI\\_time, AKI\\_status) \\textasciitilde{} age + age\\_square + male + male\\_CKD\\_stage\\_G3a + age\\_BMI\\_TC'"
      ],
      "text/markdown": [
       "'Surv(AKI_time, AKI_status) ~ age + age_square + male + male_CKD_stage_G3a + age_BMI_TC'"
      ],
      "text/plain": [
       "[1] \"Surv(AKI_time, AKI_status) ~ age + age_square + male + male_CKD_stage_G3a + age_BMI_TC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save.image(\"model_train_workspace.Rdata\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
